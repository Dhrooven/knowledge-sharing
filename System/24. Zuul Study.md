## Case study: Zuul from Netflix

Zuul is an L7 application gateway that provides capabilities for dynamic routing, monitoring, resiliency, security, and more.


### Architecture

<img width="642" alt="image" src="https://user-images.githubusercontent.com/47337188/170803366-54f86d7e-c8b6-4663-8c08-81b4cb32a2de.png">

The **Netty handlers** on the front and back of the filters are mainly responsible for handling the **network protocol, web server, connection management and proxying work**. With those inner workings abstracted away, the filters do all of the heavy lifting:


* The **inbound** filters run before proxying the request and can be used for **authentication, routing, or decorating the request**.
* The **endpoint** filters can either be used to return a **static response** or **proxy** the request to the backend service (or origin as we call it).
* The **outbound** filters run after a response has been returned and can be used for things like **gzipping, metrics, or adding/removing custom headers**.

Zuul’s functionality depends almost entirely on the logic that you add in each **filter**. That means you can deploy it in multiple contexts。

### Approach

An overarching idea was that while the best source of data for a servers’ **latency** is the **client-side** view, the best source of data on a servers’ **utilization** is from the **server** itself.

And that combining these 2 sources of data should give us the most effective load-balancing.

* A choice-of-2 algorithm to choose between servers.
* Primarily balance based on the load balancers’ view of a servers’ utilization.
* Secondarily balance based on the servers’ view of its utilization.

#### Combining Join-the-Shortest-Queue(JSQ) with Server-Reported Utilization

**Problems with JSQ**

JSQ is generally implemented by counting the number of in-use connections to a server from only the **local** load balancer. It works very well for a **single** load-balancer, but has a significant problem if used in isolation across a cluster of load balancers.

<img width="696" alt="image" src="https://user-images.githubusercontent.com/47337188/170803502-4993a730-7a98-4257-a60e-7c1ef789d1c8.png">

That illustrates how a single load balancers’ viewpoint can be entirely different from the actual reality.

One solution to this problem could be to **share** the **state** of each load balancers’ inflight counts with all other load balancers … but then you have a **distributed state problem** to solve.

An alternative simpler solution — and one that we’ve chosen — is to instead rely on the servers reporting to each load balancer how utilized they are.

**Server-Reported Utilization**

Using each server’s viewpoint on their utilization has the advantage that it provides the aggregate of all load balancers that are using that server, and therefore avoids the JSQ problem of an incomplete picture.

There were 2 ways we could have implemented this — either:

* **Actively** **poll** for each servers’ current utilization using health-check endpoints.
* **Passively** **track** **responses** from the servers **annotated** with their current **utilization** data.

We chose the 2nd option, as it was simple, allowed for frequent updating of this data, and avoided the additional load placed on servers of having N load balancers poll M servers every few seconds.

An impact of this passive strategy is that the more frequently a load balancer sends a request to one server, the more up-to-date it’s view of that servers’ utilization.

#### Choice-of-2 Algorithm Instead of Round-Robin

<img width="496" alt="image" src="https://user-images.githubusercontent.com/47337188/170803582-bc349e26-3f7a-4c1e-8452-d4603b82f747.png">

So far, we’ve had one guide (that is, load balancer) with a complete view of the queues and response time in the arrivals hall. That guide tries to make the best choice for each traveler based on the information he knows.

Now consider what happens if we have several guides, each directing travelers independently. The guides have independent views of the queue lengths and queue wait times – they only consider the travelers that they send to each queue.

So approaches above don’t work well with multiple “guides”(load balancers).

Instead of making the absolute best choice using incomplete data, with “power of two choices” you pick two queues at random and chose the better option of the two, avoiding the worse choice.

“Power of two choices” is efficient to implement. You don’t have to compare all queues to choose the best option each time; instead, you only need to compare two. And, perhaps unintuitively, it works **better at scale than the best choice** algorithms. It **avoids** the undesired **herd** behavior by the simple approach of avoiding the worst queue and distributing traffic with a degree of **randomness**.

In Zuul, Random with Two Choices chooses between **two randomly** selected servers based on which currently has **fewer active connections**. This is the same selection criterion as used for the Least Connections algorithm.

**Choice-of-2 Algorithm**


#### Choose based on Combination of Factors

* Client Health: rolling percentage of connection-related errors for that server.
* Server Utilization: most recent score provided by that server.
* Client Utilization: current number of inflight requests to that server from this load balancer.

These 3 factors are used to assign scores to each server, and then the aggregate scores are compared to choose the winner.

Using multiple factors like this does make the implementation more complicated, but it hedges against edge-case problems that can occur from relying solely on one factor.

*References

[https://netflixtechblog.com/open-sourcing-zuul-2-82ea476cb2b3](https://netflixtechblog.com/open-sourcing-zuul-2-82ea476cb2b3)

[https://netflixtechblog.com/netflix-edge-load-balancing-695308b5548c](https://netflixtechblog.com/netflix-edge-load-balancing-695308b5548c)

[https://www.nginx.com/blog/nginx-power-of-two-choices-load-balancing-algorithm/](https://www.nginx.com/blog/nginx-power-of-two-choices-load-balancing-algorithm/)
