# Event Streaming Platform

Today, data is in motion, and engineering teams need to model applications to process business requirements as streams of events, not as data at rest, sitting idly in a traditional data store.

## Architecture

An example model looks as below

![image](https://user-images.githubusercontent.com/47337188/177908147-08e60b67-b681-41f7-8a90-9eabad2a5b74.png)

We can design business processes and applications around Event Streams. Everything, from sales, orders, trades, and customer experiences to sensor readings and database updates, is modeled as an Event. Events are written to the Event Streaming Platform once, allowing distributed functions within the business to react in real time. Systems external to the Event Streaming Platform are integrated using Event Sources and Event Sinks. Business logic is built within Event Processing Applications, which are composed of Event Processors that read events from and write events to Event Streams.

### Table

#### Projection Table

How can a stream of change events be efficiently summarized to give the current state of the world?

![image](https://user-images.githubusercontent.com/47337188/178018024-2567badb-9df6-4a8e-8214-db5646ad7a2b.png)

We can maintain a projection table that behaves just like a materialized view in a traditional database. 

As new events come in, the table is automatically updated, constantly giving us a live picture of the system. 

Events with the same key are considered related; newer events are interpreted, depending on their contents, as updates to or deletions of older events.

As with a materialized view, projection tables are read-only. To change a projection table, we change the underlying data by recording new events to the table's underlying stream.

ksqlDB supports easy creation of summary tables and materialized views. We declare them once, and the server will maintain their data as new events stream in.

#### State Table

How can an Event Processor manage mutable state, similar to how a table does in a relational database?

![image](https://user-images.githubusercontent.com/47337188/178017305-b9e743b1-f0a0-4fe8-8b10-f185d7c44b55.png)

Event Processors often need to perform stateful operations, such as an aggregation (for example, counting the number of events). The state is similar to a table in a relational database, and is mutable: it allows for read and write operations. 

It is essential that the event processor has an efficient and fault-tolerant mechanism for state management--for recording and updating the state while processing input events--to ensure correctness of the computations and to prevent data loss and data duplication.

We need to implement a mutable state table that allows the Event Processor to record and update state. For example, to count the number of payments per customer, a state table provides a mapping between the customer (for example, a customer ID) and the current count of payments.

The state's storage backend can vary by implementation: options include local state stores (such as RocksDB), remote state stores (such as Amazon DynamoDB or a NoSQL database), and in-memory caches. Local state stores are usually recommended, as they do not incur additional latency for network round trips, and this improves the end-to-end performance of the Event Processor.

The streaming database ksqlDB provides state tables out of the box with its TABLE data collection. The implementation uses local, fault-tolerant state stores that are continuously backed up into ksqlDB's distributed storage layer -- Kafka -- so that the data is durable.

### 

#### ksqlDB

The database purpose-built for stream processing applications.

![image](https://user-images.githubusercontent.com/47337188/178019412-191c6f14-3314-45a1-899a-372ec1034049.png)

#### Apache Kafka

Apache Kafka is an open-source distributed event streaming platform.

It is a distributed system consisting of servers and clients that communicate via a high-performance TCP network protocol. It can be deployed on bare-metal hardware, virtual machines, and containers in on-premise as well as cloud environments.

**Servers**

Kafka is run as a cluster of one or more servers that can span multiple datacenters or cloud regions. 

Some of these servers form the storage layer, called the brokers. 

Other servers run Kafka Connect to continuously import and export data as event streams to integrate Kafka with your existing systems such as relational databases as well as other Kafka clusters. 

To let you implement mission-critical use cases, a Kafka cluster is highly scalable and fault-tolerant: if any of its servers fails, the other servers will take over their work to ensure continuous operations without any data loss.

**Clients**

They allow you to write distributed applications and microservices that read, write, and process streams of events in parallel, at scale, and in a fault-tolerant manner even in the case of network problems or machine failures.



## *References
https://developer.confluent.io/patterns/event-stream/event-streaming-platform/

https://ksqldb.io/

https://kafka.apache.org/intro



